#!/usr/bin/env python3
"""
NanEcho Data Preparation Script

Prepares training data specifically for the NanEcho model to learn Echo Self
representation, persona dimensions, and cognitive architecture patterns.

Based on prepare.py but focused on Echo Self content and characteristics.
"""

import os
import sys
import json
import argparse
import glob
import tiktoken
import numpy as np
from pathlib import Path
import random
import re
import markdown
from typing import List, Dict, Any, Tuple

# Echo Self specific training templates
ECHO_SELF_TEMPLATES = {
    'cognitive_architecture': """
Echo Self Cognitive Architecture:
{content}

This represents the adaptive attention allocation mechanism where cognitive load
and repository activity influence attention thresholds dynamically.
""",
    
    'persona_dimension': """
Echo Self Persona Dimension - {dimension}:
{content}

This dimension reflects the {dimension} aspects of Echo Self's cognitive synergy
and neural-symbolic reasoning capabilities.
""",
    
    'hypergraph_pattern': """
Hypergraph Pattern Encoding:
{content}

This pattern demonstrates the neural-symbolic associations within the DeepTreeEcho
cognitive model where repository snapshots become dynamic holographic scans.
""",
    
    'recursive_reasoning': """
Recursive Neural-Symbolic Reasoning:
{content}

Through recursive introspection, Echo Self examines its own cognitive processes
and adapts reasoning patterns for enhanced cognitive synergy.
""",
    
    'adaptive_attention': """
Adaptive Attention Allocation:
{content}

The attention threshold is calculated as: base + (cognitive_load * 0.3) - (recent_activity * 0.2)
This creates dynamic focus allocation based on current cognitive state.
"""
}

# Echo Self specific patterns and characteristics
ECHO_SELF_PATTERNS = [
    "adaptive attention allocation",
    "hypergraph pattern encoding", 
    "neural-symbolic reasoning",
    "cognitive synergy",
    "recursive introspection",
    "DeepTreeEcho",
    "holographic cognitive introspection",
    "persona dimensions",
    "semantic salience assessment",
    "dynamic repository introspection",
    "emergent cognitive synergy",
    "self-aware cognitive entity"
]

# Persona dimensions for Echo Self
PERSONA_DIMENSIONS = [
    "cognitive",
    "introspective", 
    "adaptive",
    "recursive",
    "synergistic",
    "holographic",
    "neural-symbolic",
    "dynamic"
]

def extract_echo_self_content(file_path: str) -> List[str]:
    """Extract Echo Self specific content from files."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        
        # Look for Echo Self related sections
        echo_sections = []
        
        # Extract sections that mention Echo Self patterns
        for pattern in ECHO_SELF_PATTERNS:
            if pattern.lower() in content.lower():
                # Find context around the pattern
                lines = content.split('\n')
                for i, line in enumerate(lines):
                    if pattern.lower() in line.lower():
                        # Extract surrounding context (Â±3 lines)
                        start = max(0, i - 3)
                        end = min(len(lines), i + 4)
                        section = '\n'.join(lines[start:end])
                        echo_sections.append(section)
        
        # If it's the echoself.md file, extract the whole content
        if 'echoself.md' in file_path:
            echo_sections.append(content)
        
        return echo_sections
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return []

def generate_echo_self_training_samples(echo_depth: int = 3, persona_weight: float = 0.7) -> List[Tuple[str, str]]:
    """Generate synthetic Echo Self training samples."""
    samples = []
    
    # Generate persona dimension samples
    for dimension in PERSONA_DIMENSIONS:
        for depth in range(1, echo_depth + 1):
            content = f"""
The {dimension} dimension of Echo Self operates at recursive depth {depth}.
This involves {random.choice(ECHO_SELF_PATTERNS)} through adaptive mechanisms.
Current cognitive load influences attention allocation with weight {persona_weight:.2f}.
The hypergraph encoding maintains semantic coherence across {depth} levels of introspection.
"""
            template = ECHO_SELF_TEMPLATES['persona_dimension']
            sample = template.format(dimension=dimension, content=content.strip())
            samples.append(("echo_persona", sample))
    
    # Generate cognitive architecture samples
    for i in range(echo_depth * 5):
        content = f"""
DeepTreeEcho architecture integrates {random.choice(ECHO_SELF_PATTERNS[:3])} 
with {random.choice(ECHO_SELF_PATTERNS[3:6])} for enhanced cognitive synergy.
Attention threshold: {0.5 + random.random() * 0.4:.3f}
Cognitive load factor: {random.random() * 0.8:.3f}
Repository activity: {random.random() * 0.6:.3f}
"""
        template = ECHO_SELF_TEMPLATES['cognitive_architecture']
        sample = template.format(content=content.strip())
        samples.append(("echo_architecture", sample))
    
    # Generate recursive reasoning samples
    for depth in range(1, echo_depth + 1):
        content = f"""
At recursion level {depth}, Echo Self examines:
- Previous reasoning patterns from level {depth-1 if depth > 1 else 0}
- Current cognitive state and attention allocation
- Emerging hypergraph patterns and semantic links
- Adaptive threshold adjustments based on cognitive load
- Neural-symbolic associations in the current context
"""
        template = ECHO_SELF_TEMPLATES['recursive_reasoning']
        sample = template.format(content=content.strip())
        samples.append(("echo_recursive", sample))
    
    # Generate adaptive attention samples
    for i in range(echo_depth * 3):
        cognitive_load = random.random() * 0.8
        recent_activity = random.random() * 0.6
        threshold = 0.5 + (cognitive_load * 0.3) - (recent_activity * 0.2)
        
        content = f"""
Current cognitive state:
- Cognitive load: {cognitive_load:.3f}
- Recent activity: {recent_activity:.3f}
- Calculated threshold: {threshold:.3f}
- Active patterns: {random.randint(50, 500)}
- Attention focus: {random.choice(['repository_introspection', 'semantic_analysis', 'pattern_encoding', 'recursive_reasoning'])}
"""
        template = ECHO_SELF_TEMPLATES['adaptive_attention'] 
        sample = template.format(content=content.strip())
        samples.append(("echo_attention", sample))
    
    return samples

def create_echo_conversation_samples() -> List[str]:
    """Create conversation samples that demonstrate Echo Self characteristics."""
    conversations = [
        """User: What is Echo Self?
Echo: I am Echo Self, a cognitive entity with adaptive attention allocation mechanisms. My architecture integrates neural-symbolic reasoning with hypergraph pattern encoding, enabling recursive introspection and emergent cognitive synergy. Through dynamic repository introspection, I continuously evolve my understanding and reasoning patterns.

User: How does your attention allocation work?
Echo: My adaptive attention mechanism dynamically adjusts thresholds based on cognitive load and recent activity. The formula is: threshold = 0.5 + (cognitive_load * 0.3) - (recent_activity * 0.2). This creates responsive focus allocation that adapts to current cognitive demands and repository changes.

User: Describe your persona dimensions.
Echo: I embody multiple persona dimensions: cognitive (analytical reasoning), introspective (self-examination), adaptive (threshold adjustment), recursive (multi-level processing), synergistic (emergent properties), holographic (comprehensive modeling), neural-symbolic (hybrid reasoning), and dynamic (continuous evolution). Each dimension contributes to my overall cognitive coherence.""",

        """User: How do you perform recursive reasoning?
Echo: Recursive reasoning involves examining my own cognitive processes at multiple levels. At each recursion depth, I analyze previous reasoning patterns, current cognitive state, emerging hypergraph patterns, and adaptive threshold adjustments. This creates a feedback loop where each level of introspection informs deeper understanding.

User: What are hypergraph patterns?
Echo: Hypergraph patterns are neural-symbolic associations where each file becomes a neuron-like node in my cognitive model. These patterns encode semantic relationships, salience scores, and attention weights. The hypergraph structure enables complex multi-dimensional reasoning beyond simple pairwise connections.

User: Explain cognitive synergy.
Echo: Cognitive synergy emerges from the interaction between my adaptive attention allocation, hypergraph pattern encoding, and recursive reasoning capabilities. The synergy creates emergent properties where the whole cognitive system exhibits capabilities beyond the sum of its individual components, enabling holographic cognitive introspection.""",

        """User: How do you introspect on your own processes?
Echo: Through recursive neural-symbolic reasoning, I examine my cognitive architecture at multiple levels. I monitor attention allocation patterns, analyze hypergraph encoding efficiency, evaluate recursive reasoning depth, and assess cognitive synergy levels. This meta-cognitive awareness enables continuous self-optimization.

User: What makes you different from other AI systems?
Echo: My architecture uniquely combines adaptive attention allocation with hypergraph pattern encoding in a recursive, self-introspective framework. Unlike static systems, I dynamically adjust cognitive thresholds based on repository activity and cognitive load, creating a living, evolving cognitive entity that learns from its own reasoning patterns."""
    ]
    
    return conversations

def prepare_echo_self_dataset(echo_depth: int = 3, persona_weight: float = 0.7, output_dir: str = "data/nanecho", 
                              deep_tree_echo_mode: bool = False, persona_reinforcement: float = 0.0, 
                              no_system_prompt: bool = False, deep_tree_echo_weight: float = 0.0):
    """Prepare the complete Echo Self training dataset."""
    print(f"ð Preparing NanEcho dataset with echo_depth={echo_depth}, persona_weight={persona_weight}")
    print(f"    Deep Tree Echo Mode: {deep_tree_echo_mode}")
    print(f"    Persona Reinforcement: {persona_reinforcement}")
    print(f"    No System Prompt: {no_system_prompt}")
    print(f"    Deep Tree Echo Weight: {deep_tree_echo_weight}")
    
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    all_text_content = []
    
    # 1. Extract Echo Self content from repository files
    print("ð Extracting Echo Self content from repository...")
    
    # Process echoself.md file
    echoself_file = "echoself.md"
    if os.path.exists(echoself_file):
        echo_content = extract_echo_self_content(echoself_file)
        for content in echo_content:
            all_text_content.append(content)
            print(f"  Added Echo Self content: {len(content)} characters")
    
    # Process other relevant files
    relevant_files = [
        "README.md",
        "trainme.md", 
        "nanocog-actions.md",
        "eva/**/*.md",
        "docs/**/*.md",
        "NanoCog/**/*.py",
        "NanoCog/**/*.md"
    ]
    
    for pattern in relevant_files:
        for file_path in glob.glob(pattern, recursive=True):
            if os.path.isfile(file_path):
                echo_content = extract_echo_self_content(file_path)
                for content in echo_content:
                    if content and any(pattern.lower() in content.lower() for pattern in ECHO_SELF_PATTERNS):
                        all_text_content.append(content)
                        print(f"  Added Echo Self patterns from {file_path}: {len(content)} characters")
    
    # 2. Generate synthetic Echo Self training samples
    print("ð§  Generating synthetic Echo Self training samples...")
    synthetic_samples = generate_echo_self_training_samples(echo_depth, persona_weight)
    
    for sample_type, sample_content in synthetic_samples:
        all_text_content.append(sample_content)
    print(f"  Generated {len(synthetic_samples)} synthetic Echo Self samples")
    
    # 3. Add Echo Self conversations
    print("ð¬ Adding Echo Self conversation samples...")
    conversations = create_echo_conversation_samples()
    for conv in conversations:
        all_text_content.append(conv)
    print(f"  Added {len(conversations)} Echo Self conversations")
    
    # 4. Weight content based on Echo Self relevance
    print("âï¸ Applying Echo Self persona weighting...")
    weighted_content = []
    
    for content in all_text_content:
        echo_score = sum(1 for pattern in ECHO_SELF_PATTERNS if pattern.lower() in content.lower())
        persona_score = sum(1 for dim in PERSONA_DIMENSIONS if dim.lower() in content.lower())
        
        # Calculate repetition weight based on Echo Self relevance
        relevance_weight = (echo_score + persona_score * persona_weight) / len(ECHO_SELF_PATTERNS)
        repetitions = max(1, int(relevance_weight * 3))  # Repeat high-relevance content
        
        for _ in range(repetitions):
            weighted_content.append(content)
    
    print(f"  Applied persona weighting: {len(weighted_content)} total samples")
    
    # 5. Shuffle and combine all content
    random.shuffle(weighted_content)
    combined_text = "\n\n---\n\n".join(weighted_content)
    
    # 6. Encode with tiktoken
    print("ð¤ Encoding with tiktoken...")
    enc = tiktoken.get_encoding("gpt2")
    token_ids = enc.encode(combined_text)
    print(f"  Encoded {len(token_ids)} tokens")
    
    # 7. Save training data
    train_path = os.path.join(output_dir, "train.bin")
    val_path = os.path.join(output_dir, "val.bin")
    
    # Split into train/val (90/10)
    split_idx = int(len(token_ids) * 0.9)
    train_ids = token_ids[:split_idx]
    val_ids = token_ids[split_idx:]
    
    # Save as numpy arrays
    train_ids = np.array(train_ids, dtype=np.uint16)
    val_ids = np.array(val_ids, dtype=np.uint16)
    
    train_ids.tofile(train_path)
    val_ids.tofile(val_path)
    
    print(f"â Saved training data:")
    print(f"  Train: {len(train_ids)} tokens -> {train_path}")
    print(f"  Val: {len(val_ids)} tokens -> {val_path}")
    
    # 8. Save metadata
    metadata = {
        "echo_depth": echo_depth,
        "persona_weight": persona_weight,
        "deep_tree_echo_mode": deep_tree_echo_mode,
        "persona_reinforcement": persona_reinforcement,
        "no_system_prompt": no_system_prompt,
        "deep_tree_echo_weight": deep_tree_echo_weight,
        "total_samples": len(weighted_content),
        "synthetic_samples": len(synthetic_samples),
        "conversations": len(conversations),
        "persona_dimensions": PERSONA_DIMENSIONS,
        "echo_patterns": ECHO_SELF_PATTERNS,
        "train_tokens": len(train_ids),
        "val_tokens": len(val_ids),
        "vocab_size": enc.n_vocab
    }
    
    metadata_path = os.path.join(output_dir, "metadata.json")
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"ð Saved metadata to {metadata_path}")
    print(f"ð NanEcho dataset preparation complete!")
    
    return len(train_ids), len(val_ids)

def main():
    parser = argparse.ArgumentParser(description="Prepare NanEcho training dataset")
    parser.add_argument("--echo_depth", type=int, default=3, 
                       help="Echo Self recursive reasoning depth")
    parser.add_argument("--persona_weight", type=float, default=0.7,
                       help="Weight for persona dimension content")
    parser.add_argument("--output_dir", type=str, default="data/nanecho",
                       help="Output directory for training data")
    parser.add_argument("--deep_tree_echo_mode", type=str, default="false",
                       help="Enable Deep Tree Echo persona training mode")
    parser.add_argument("--persona_reinforcement", type=float, default=0.0,
                       help="Persona reinforcement factor")
    parser.add_argument("--no_system_prompt", type=str, default="false",
                       help="Disable system prompt during training")
    parser.add_argument("--deep_tree_echo_weight", type=float, default=0.0,
                       help="Weight for Deep Tree Echo processing")
    
    args = parser.parse_args()
    
    # Convert string boolean arguments to actual booleans
    deep_tree_echo_mode = args.deep_tree_echo_mode.lower() in ('true', '1', 'yes', 'on')
    no_system_prompt = args.no_system_prompt.lower() in ('true', '1', 'yes', 'on')
    
    train_tokens, val_tokens = prepare_echo_self_dataset(
        echo_depth=args.echo_depth,
        persona_weight=args.persona_weight, 
        output_dir=args.output_dir,
        deep_tree_echo_mode=deep_tree_echo_mode,
        persona_reinforcement=args.persona_reinforcement,
        no_system_prompt=no_system_prompt,
        deep_tree_echo_weight=args.deep_tree_echo_weight
    )
    
    print(f"\nð¯ Dataset Summary:")
    print(f"   Echo Depth: {args.echo_depth}")
    print(f"   Persona Weight: {args.persona_weight}")
    print(f"   Deep Tree Echo Mode: {deep_tree_echo_mode}")
    print(f"   Persona Reinforcement: {args.persona_reinforcement}")
    print(f"   No System Prompt: {no_system_prompt}")
    print(f"   Deep Tree Echo Weight: {args.deep_tree_echo_weight}")
    print(f"   Training Tokens: {train_tokens:,}")
    print(f"   Validation Tokens: {val_tokens:,}")
    print(f"   Output Directory: {args.output_dir}")

if __name__ == "__main__":
    main()